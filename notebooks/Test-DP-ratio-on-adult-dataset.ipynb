{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What this notebook does?**\n",
    "\n",
    "Experiment to **Demographic Parity Ratio** constraint on adult dataset.\n",
    "\n",
    "Things to note:\n",
    "1. Input - Adult dataset from shap. Sensitive feature = 'Sex'\n",
    "2. Classifier - LogististicRegression from sklearn library.\n",
    "3. Constraint evaluted - Demographic Parity with ratio = 0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "from fairlearn.reductions import GridSearch\n",
    "from fairlearn.reductions import DemographicParity\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw, Y = shap.datasets.adult()\n",
    "sensitive_attribute = 'Sex'\n",
    "\n",
    "A = X_raw[sensitive_attribute]\n",
    "X = X_raw.drop(labels=[sensitive_attribute],axis = 1)\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "\n",
    "X = X.reset_index(drop=True)\n",
    "A = A.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmitigated_predictor = LogisticRegression(fit_intercept=True, solver='liblinear')\n",
    "unmitigated_predictor.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(y, predicted_y):\n",
    "    correct_y = (y == predicted_y)\n",
    "    return 1 - sum(correct_y)/len(correct_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmitigated_y = pd.Series(unmitigated_predictor.predict(X), name=\"unmitigated_predicted_y\")\n",
    "error_unmitigated = [get_error(Y, unmitigated_y)]\n",
    "print(\"The error for unmitigated is:\", error_unmitigated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dp_violation(predict_y, A, ratio, label_name):\n",
    "    violations = []\n",
    "    predicted_and_sensitive_feature = pd.concat([predict_y, A],axis=1)\n",
    "    grouped = predicted_and_sensitive_feature.groupby(sensitive_attribute)\n",
    "    counts_by_group = grouped[[label_name]].count()\n",
    "    passed_by_group = grouped[[label_name]].sum()\n",
    "    \n",
    "    for i,group in enumerate(grouped.groups.keys()):\n",
    "        violation_1 = passed_by_group[label_name][i] / counts_by_group[label_name][i]\n",
    "        violation_2 = sum(predict_y) / len(predict_y)\n",
    "        # ratio <= E[h(x)| A = a]/E[h(x)] <= 1/ratio \n",
    "        # 1. - E[h(x)| A = a] + ratio * E[h(x)] <= 0\n",
    "        # 2. ratio * E[h(x)| A = a] - E[h(x)] <= 0\n",
    "        violations.append(abs(violation_1 - (ratio * violation_2)))\n",
    "        violations.append(abs((ratio * violation_1) - violation_2))\n",
    "    violation = max(violations)\n",
    "    return violation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairlearn.reductions import ExponentiatedGradient\n",
    "from fairlearn.reductions import GridSearch, DemographicParity\n",
    "import numpy as np\n",
    "eps_list = [0.001]\n",
    "expgrad_error = []\n",
    "dp_expgrad_violation = []\n",
    "ratio = 0.8\n",
    "for eps in eps_list:\n",
    "    expgrad_X = ExponentiatedGradient(\n",
    "    LogisticRegression(fit_intercept=True, solver='liblinear'),\n",
    "    constraints=DemographicParity(ratio=ratio),\n",
    "    eps=eps, nu=1e-6)\n",
    "    \n",
    "    expgrad_X.fit(X, Y, sensitive_features=A)\n",
    "    \n",
    "    expgrad_y = pd.Series(expgrad_X.predict(X),name=\"expgrad_predicted_y\")\n",
    "    error_expgrad = get_error(Y, expgrad_y)\n",
    "    expgrad_error.append(error_expgrad)\n",
    "    dp_violation_expgrad = get_dp_violation(expgrad_y, A, ratio,\"expgrad_predicted_y\")\n",
    "    dp_expgrad_violation.append(dp_violation_expgrad)\n",
    "    \n",
    "dp_violation_unmitigated = [get_dp_violation(unmitigated_y, A, ratio, 'unmitigated_predicted_y')]\n",
    "print(\"The violation for unmitigated is {} and mitigated is {}:\".format(\n",
    "    dp_violation_unmitigated, dp_expgrad_violation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(dp_expgrad_violation, expgrad_error, label=\"expgrad\")\n",
    "plt.plot(dp_violation_unmitigated, error_unmitigated, 'ro', label=\"unmitigated\")\n",
    "plt.xlabel('Violation of the fairness constraint')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Adult Uci/DP/log.reg')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
