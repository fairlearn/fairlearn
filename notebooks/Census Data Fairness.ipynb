{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Fairlearn with Census Data\n",
    "\n",
    "This notebook shows how to use `fairlearn` and the Fairness dashboard to generate models for the Census dataset. This dataset is a classification problem - given a range of data about 32,000 individuals, predict whether their annual income is above or below fifty thousand dollars per year.\n",
    "\n",
    "Income data are well known to have biases; in this case, we will attempt to mitigate the bias based on sex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess the Dataset\n",
    "\n",
    "For simplicity, we import the dataset from the `shap` package, which contains the data in a cleaned format. We start by importing the various modules we're going to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from fairlearn.metrics import DemographicParity\n",
    "from fairlearn.reductions import GridSearch\n",
    "from fairlearn.reductions.grid_search.simple_quality_metrics import SimpleClassificationQualityMetric\n",
    "from fairlearn.moments import MisclassificationError, DP\n",
    "\n",
    "from sklearn import svm, neighbors, tree\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import shap\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(sys.version)\n",
    "\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load and inspect the data from the `shap` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw,y = shap.datasets.adult()\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to treat the sex of each individual as a protected attribute, and in this particular case we are going separate it out and drop it from the main data. We then perform some standard data preprocessing steps to convert the data into a format suitable for the ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = X_raw[\"Sex\"]\n",
    "X = X_raw.drop(labels=['Sex'],axis = 1)\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_scaled = sc.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we now perform the normal split of the data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test, a_train, a_test = train_test_split(X_scaled, \n",
    "                                                    y, \n",
    "                                                    A,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state=0,\n",
    "                                                    stratify=y)\n",
    "\n",
    "# Work around indexing bug\n",
    "x_train = x_train.reset_index(drop=True)\n",
    "a_train = a_train.reset_index(drop=True)\n",
    "x_test = x_test.reset_index(drop=True)\n",
    "a_test = a_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an unmitigated model\n",
    "\n",
    "To show the effect of `fairlearn` we will first train a model without it. For speed of demonstration, we use a simple logistic regression learner from `sklearn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmitigated_model = LogisticRegression(solver='liblinear', fit_intercept=True)\n",
    "\n",
    "unmitigated_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load this model into the Fairness dashboard, and examine how it is unfair (there is a warning about AzureML since we are not yet integrated with that product):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.explain.model.visualize import FairnessDashboard\n",
    "\n",
    "FairnessDashboard(unmitigated_model, x_test, y_test.tolist(), pd.DataFrame(a_test).values.tolist(), True, list(x_test.columns), [0, 1], [\"Sex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm pretty sure that something can be seen, but the widget isn't co-operating for me right now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigation with GridSearch\n",
    "\n",
    "The `GridSearch` class in `fairlearn` implements a simplified version of the exponentiated gradient algorithm of ([Agarwal et al. 2018](https://arxiv.org/abs/1803.02453)). By restricting the problem domain to binary classifiers with binary protected attributes, the exponentiated gradient algorithm can be reduced to trying a sequence of reweightings and relabellings of the training data. This sequence is parameterised by $\\lambda$ since in the full algorithm, the sweep comes from a Lagrange multiplier.\n",
    "\n",
    "To work, `GridSearch` requires an underlying learner (we shall use the same `LogisticRegression` learner as above), a fairness metric, and a quality metric.\n",
    "\n",
    "For this example, we specify demographic parity (on the protected attribute of \"sex\") as the fairness metric. This is for simplicity; in general, the appropriate fairness metric will depend on the problem specification.\n",
    "\n",
    "The particular quality metric is not relevant in this case, since we are going to inspect a collection of models. It is used to select one of the models for the `GridSearch.fit()` method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep = GridSearch(LogisticRegression(solver='liblinear', fit_intercept=True),\n",
    "                   fairness_metric=DemographicParity(),\n",
    "                   quality_metric=SimpleClassificationQualityMetric())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our algorithms provide `fit()` and `predict()` methods, so they behave in a similar manner to other ML packages in Python. We do however have to specify two extra arguments to `fit()` - the column of protected attribute labels, and also the number of values we wish to use for the Lagrange multiplier. The grid search will call the underlying learner once for each value, making it an ideal point to integrate with AzureML and leverage large scale execution in the cloud.\n",
    "\n",
    "After `fit()` completes, we extract the full set of models from the `GridSearch` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep.fit(x_train, y_train,\n",
    "          protected_attribute=a_train,\n",
    "          number_of_lagrange_multipliers=71)\n",
    "\n",
    "models = [ x[\"model\"] for x in sweep.all_models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could load these models into the Fairness dashboard now. However, the plot would be somewhat confusing due to their number. In this case, we are going to remove the models which are dominated in the accuracy-parity space by others from the sweep (note that the parity will only be calculated for the protected attribute; other potentially protected attributes will not be mitigated). In general, one might not want to do this, since there may be other considerations beyond the strict maximisation of accuracy and parity (of the given protected attribute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors, disparities = [], []\n",
    "for m in models:\n",
    "    classifier = lambda X: m.predict(X)\n",
    "    \n",
    "    error = MisclassificationError()\n",
    "    error.init(x_test, a_test, pd.Series(y_test))\n",
    "    disparity = DP()\n",
    "    disparity.init(x_test, a_test, pd.Series(y_test))\n",
    "    \n",
    "    errors.append(error.gamma(classifier)[0])\n",
    "    disparities.append(disparity.gamma(classifier).max())\n",
    "    \n",
    "all_results = pd.DataFrame( {\"model\": m, \"error\": errors, \"disparity\": disparities})\n",
    "non_dominated = []\n",
    "for row in all_results.itertuples():\n",
    "    errors_for_lower_or_eq_disparity = all_results[\"error\"][all_results[\"disparity\"]<row.disparity]\n",
    "    if row.error <= errors_for_lower_or_eq_disparity.min():\n",
    "        non_dominated.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can put the non-dominated into the Fairness dashboard. We also add in the original, unmitigated model - it will be the one highlighted when the dashboard first loads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard_models = [unmitigated_model]\n",
    "dashboard_models.append([x.model for x in non_dominated])\n",
    "\n",
    "FairnessDashboard(models, x_test, y_test.tolist(), pd.DataFrame(a_test).values.tolist(), True, list(x_test.columns), [0, 1], [\"Sex\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this you can.... play around and see things?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
